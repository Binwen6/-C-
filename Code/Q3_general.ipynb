{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Dataset         Model  Accuracy      AUC  F1-score  Type I Error  Type II Error\n",
      "    German Credit       XGBoost  0.742000 0.772571  0.527484      0.092199       0.457627\n",
      "    German Credit Decision Tree  0.682000 0.622857  0.472862      0.234043       0.525424\n",
      "    German Credit Random Forest  0.754000 0.791429  0.493269      0.070922       0.610169\n",
      "    German Credit           SVM  0.763000 0.784952  0.493618      0.070922       0.559322\n",
      "Australian Credit       XGBoost  0.875362 0.927706  0.886974      0.176471       0.114943\n",
      "Australian Credit Decision Tree  0.817391 0.798772  0.830623      0.215686       0.126437\n",
      "Australian Credit Random Forest  0.863768 0.931816  0.873536      0.196078       0.068966\n",
      "Australian Credit           SVM  0.853623 0.912786  0.862179      0.196078       0.126437\n",
      "\n",
      "Results saved to 'credit_model_comparison_results.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n",
    "\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    accuracy = cv_scores.mean()\n",
    "    auc = cross_val_score(model, X, y, cv=5, scoring='roc_auc').mean()\n",
    "    f1 = cross_val_score(model, X, y, cv=5, scoring='f1').mean()\n",
    "    \n",
    "    # Calculate Type I and Type II errors\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    type1_error = fp / (fp + tn)\n",
    "    type2_error = fn / (fn + tp)\n",
    "    \n",
    "    return accuracy, auc, f1, type1_error, type2_error\n",
    "\n",
    "def analyze_dataset(df, target_column, dataset_name):\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    \n",
    "    models = {\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'SVM': SVC(probability=True)\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        accuracy, auc, f1, type1_error, type2_error = evaluate_model(model, X, y)\n",
    "        results.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy,\n",
    "            'AUC': auc,\n",
    "            'F1-score': f1,\n",
    "            'Type I Error': type1_error,\n",
    "            'Type II Error': type2_error\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Load datasets\n",
    "german_df = pd.read_csv('..\\Data\\data1.csv')\n",
    "australian_df = pd.read_csv('..\\Data\\data2.csv')\n",
    "\n",
    "# Analyze German Credit Dataset\n",
    "german_results = analyze_dataset(german_df, 'Y(1=default, 0=non-default)', 'German Credit')\n",
    "\n",
    "# Analyze Australian Credit Dataset\n",
    "australian_results = analyze_dataset(australian_df, 'Y(1=default, 0=non-default)', 'Australian Credit')\n",
    "\n",
    "# Combine results\n",
    "all_results = pd.concat([german_results, australian_results])\n",
    "\n",
    "# Display results\n",
    "print(all_results.to_string(index=False))\n",
    "\n",
    "# Save results to CSV\n",
    "all_results.to_csv('..\\Data\\credit_model_comparison_results.csv', index=False)\n",
    "print(\"\\nResults saved to 'credit_model_comparison_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorchgpuEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
